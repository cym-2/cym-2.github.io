<!DOCTYPE html><html lang="en" mode="dark" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>ai basic 2 | CYM</title><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="ai basic 2" /><meta name="author" content="CYM" /><meta property="og:locale" content="en_US" /><meta name="description" content="Neural network" /><meta property="og:description" content="Neural network" /><link rel="canonical" href="http://0.0.0.0:4000/posts/ab2/" /><meta property="og:url" content="http://0.0.0.0:4000/posts/ab2/" /><meta property="og:site_name" content="CYM" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-01-15T22:00:00+00:00" /><meta name="google-site-verification" content="" /> <script type="application/ld+json"> {"description":"Neural network","headline":"ai basic 2","dateModified":"2021-01-15T22:00:00+00:00","datePublished":"2021-01-15T22:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/posts/ab2/"},"url":"http://0.0.0.0:4000/posts/ab2/","author":{"@type":"Person","name":"CYM"},"@type":"BlogPosting","@context":"https://schema.org"}</script> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">CYM</a></div><div class="site-subtitle font-italic">Study Archive Devlog</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/cym-2" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href=" javascript:window.open('mailto:' + ['cym.7172','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>ai basic 2</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>ai basic 2</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Fri, Jan 15, 2021, 10:00 PM +0000" > Jan 15 <i class="unloaded">2021-01-15T22:00:00+00:00</i> </span> by <span class="author"> CYM </span></div></div><div class="post-content"><h1 id="neural-network">Neural network</h1><p><br /> <br /></p><p><strong>0050.</strong> <br /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre><td class="rouge-code"><pre># 2-3-2-2

def sigmoid(x):
  return 1 / (1 + np.exp(-x))


def identity_function(): # 출력층의 활성화 함수. 입력을 그대로 출력하는 항등함수.
  return x


def init_network():
  network = {}
  network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])
  network['b1'] = np.array([0.1, 0.2, 0.3])
  network['W2'] = np.array([0.1, 0.4], [0.2, 0.5], [0.3, 0.6])
  network['b2'] = np.array([0.1, 0.2])
  network['W3'] = np.array([0.1, 0.3], [0.2, 0.4])
  network['b3'] = np.array([0.1, 0.2])
  
  return network


def forward(network, x):
  W1, W2, W3 = network['W1'], network['W2'], network['W3']
  b1, b2, b3 = network['b1'] ,network['b2'], network['b3']
  
  a1 = np.dot(x, W1) + b1
  z1 = sigmoid(a1)
  a2 = np.dot(z1, W2) + b2
  z2 = sigmoid(a2)
  a3 = np.dot(z2, W3) + b3
  y = identity_fuction(a3)
  
  return y


network = init_network()
x = np.array([1.0, 0.5])
y = forward(network, x)
print(y)
</pre></table></code></div></div><p><br /></p><hr /><p><br /></p><p><strong>0051.</strong> 분류: 데이터가 어느 클래스에 속하느냐. (성별분류) -&gt; 소프트맥스 함수<br /> <br /></p><p><strong>0052.</strong> 회귀: 입력 데이터에서 (연속적인) 수치를 예측. (몸무게) -&gt; 항등 함수: 입력을 그대로 출력<br /> <br /></p><p><strong>0053.</strong> 소프트맥스 함수<br /></p><ul><li>지수함수는 쉽게 아주 큰 값을 내뱉음. 이런 큰 값끼리 나눗셈을 하면 결과 수치가 ‘불안정’해짐. (오버플로)<br /><ul><li>기존의 소프트맥스 함수에 C라는 임의의 정수를 분자와 분모 양 쪽에 곱함.<br /></li><li>C를 지수 함수 exp() 안으로 옮겨 logC로 만들음.<br /></li><li>logC를 C’라는 새로운 기호로 바꿈. C’에 어떤 값을 대입해도 상관 없지만, 오버플로를 막을 목적으로는 입력 신호 중 최댓값을 이용하는 것이 일반적.<br /></li></ul></li></ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://e2eml.school/images/softmax/def_04_eq.png" alt="img" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>def softmax(a):
  c = np.max(a)
  exp_a = np.exp(a - c)
  sum_exp_a = np.sum(exp_a)
  y = exp_a / sum_exp_a
  
  return y

a = np.array([0.3, 2.9, 4.0])
y = softmax(a)
</pre></table></code></div></div><p><br /></p><p><strong>0054.</strong> 소프트맥스 함수의 출력은 0에서 1.0 사이의 실수이고 소프트맥스 함수 출력의 총합은 1 -&gt; 소프트맥스 함수의 출력을 ‘확률’로 해석할 수 있음.<br /> <br /></p><p><strong>0055.</strong> 기계학습의 문제 풀이는 학습과 추론의 두 단계를 거쳐 이루어짐. 학습 단계에서 모델을 학습하고(직업 훈련을 받고), 추론 단계에서 앞서 학습한 모델로 미지의 데이터에 대해서 추론(분류)을 수행함(현장에 나가 진짜 일을 함). 추론 단계에서는 출력층의 소프트맥스 함수를 생략하는 것이 일반적. 신경망을 학습시킬 때는 출력층에서 소프트맥스 함수를 사용. <br /></p><hr /><p><br /></p><p><strong>0056.</strong> 정규화: 데이터를 특정 범위로 변환하는 처리<br /> <br /></p><p><strong>0057.</strong> 전처리: 신경망의 입력 데이터에 특정 변환을 가하는 것.<br /></p><ul><li>ex) 입력 이미지 데이터에 대한 전처리 작업으로 정규화 수행.</li></ul><p><br /></p><p><strong>0058.</strong> 배치 처리를 수행함으로써 큰 배열로 이루어진 계싼을 하게 되는데, 컴퓨터에서는 큰 배열을 한꺼번에 계산하는 것이 분활된 작은 배열을 여러 번 검사하는 것보다 빠름.<br /> <br /> <br /> <br /> <br /> <br /></p><h1 id="neural-network-learning">Neural network learning</h1><p><br /> <br /></p><p><strong>0059.</strong> 손실함수: 신경망이 학습할 수 있도록 해주는 지표. 이 손실 함수의 결괏값을 가장 작게 만드는 가중치 매개변수를 찾는 것이 학습의 목표.<br /> <br /></p><p><strong>0060.</strong> 특징: 입력 데이터에서 본질적인 데이터(중요한 데이터)를 정확하게 추출할 수 있도록 설계된 변환기<br /> <br /></p><p><strong>0061.</strong> 딥러닝을 종단간 기계학습(end-to-end machine learning)이라고도 함. 데이터(입력)에서 목표한 결과(출력)를 사람의 개입 없이 얻었다는 뜻.<br /> <br /></p><p><strong>0062.</strong> 우리가 원하는 것은 범용적으로 사용할 수 있는 모델이라 훈련 데이터와 시험 데이터로 나눠 학습과 실험을 수행함.<br /> <br /></p><p><strong>0063.</strong> 범용 능력: 아직 보지 못한 데이터(훈련 데이터에 포함되지 않은 데이터)로도 문제를 올바르게 풀어내는 능력.<br /> <br /></p><p><strong>0064.</strong> 오버피팅: 한 데이터셋에만 지나치게 최적화된 상태.<br /> <br /></p><hr /><p><br /></p><p><strong>0065.</strong> 신경망 학습에서는 현재의 상태를 ‘하나의 지표’로 표현함. 그 지표를 가장 좋게 만들어주는 가중치 매개변수의 값을 탐색함. 신경망 학습에서 사용하는 지표는 손실 함수(loss function)라고 함. 손실 함수는 신경망 성능의 ‘나쁨’을 나타내는 지표. 일반적으로 오차제곱합과 교체 엔트로피 오차를 사용.<br /> <br /></p><p><strong>0066.</strong> 오차제곱합(sum of squares for error, SSE)<br /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://t1.daumcdn.net/cfile/tistory/9993853E5DA0704224" alt="img" /></p><ul><li>yk는 신경망의 출력(신경망이 추정한 값), tk는 정답 레이블, k는 데이터의 차원 수, 1/2는 미분을 쉽게하기 위해.<br /></li><li>각 원소의 출력(추정 값)과 정답 레이블(참 값)의 차를 제곱한 후, 그 총합을 구함.<br /></li></ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>def sum_squares_error(y, t):
  return 0.5 * np.sum((y-t)**2)
</pre></table></code></div></div><p><br /></p><p><strong>0067.</strong> 원핫인코딩: 한 원소만 1로 하고 그 외는 0으로 나타내는 표기법.<br /> <br /></p><p><strong>0068.</strong> 교차 엔트로피 오차(cross entropy error, CEE)<br /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://t1.daumcdn.net/cfile/tistory/9914B5395DA071AA10" alt="img" /></p><ul><li>yk는 신경망의 출력, tk는 정답 레이블.</li><li>실질적으로 정답일 때의 추정(tk가 1일 때의 yk)의 자연로그를 계산.</li><li>교차 엔트로피 오차는 정답일 때의 출력이 전체 값을 정함.</li><li>자연로그 y=logx의 그래프는 x가 1일 때 y는 0이 되고 x가 0에 가까워질수록 y의 값은 점점 작아짐.</li></ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>def cross_entropy_error(y, t): # y와 t는 넘파이 배열
  delta = 1e-7 # np.log() 함수에 0을 입력하면 마이너스 무한대를 뜻하는 -inf가 되어 더 이상 계산할 수 없음. 아주 작은 값을 더해서 방지 
  return -np.sum(t * np.log(y + delta))
</pre></table></code></div></div><p><br /></p><hr /><p><br /></p><p><strong>0069.</strong> 훈련 데이터 모두에 대한 손실함수의 합을 구하는 방법. ex) 교차 엔트로피 오차<br /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcPYExj%2FbtqLTxk2AEk%2FjkF2MUUthy2Mja8hFsKwB0%2Fimg.png" alt="img" /></p><ul><li>N으로 나눔으로써 ‘평균 손실 함수’를 구하는 것.<br /></li></ul><p><br /></p><p><strong>0070.</strong> 미니배치: 훈련 데이터로부터 일부만 골라 학습을 수행.<br /></p><ul><li>가령 60,000장의 훈련 데이터 중에서 100장을 무작위로 뽑아 그 100장만을 사용하여 학습.<br /></li></ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>def cross_entropy_error(y, t): # (배치용) 교체 엔트로피 오차 구현하기
  if y.ndim == 1: # y가 1차원이라면, 즉 데이터 하나당 교차 엔트로피 오차를 구하는 경우 reshape 함수로 데이터의 형상을 바꿔줌.
    t = t.reshape(1, t.size)
    y = y.reshape(1, y.size)
    
  batch_size = y.shape[0]
  return -np.sum(t * np.log(y + 1e-7)) / batch_size
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>def cross_entropy_error(y, t): # 정답 레이블이 원핫인코딩이 아니라 '2', '7' 등의 숫자 레이블로 주어졌을 때
  if y.ndim == 1:
    t = t.reshape(1, t.size)
    y = y.reshape(1, y.size)
    
  batch_size = y.shape[0]
  return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size
</pre></table></code></div></div><p><br /></p><p><strong>0071.</strong> 신경망 학습에서는 최적의 매개변수(가중치와 편향)를 탐색할 때 손실 함수의 값을 가능한 한 작게 하는 매개변수 값을 찾음.<br /> <br /></p><p><strong>0072.</strong> 이때 매개변수의 미분(정확히는 기울기)을 계산하고, 그 미분 값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복.<br /> <br /></p><p><strong>0073.</strong> 가중치 매개변수(x)의 손실 함수(f(x))의 미분: 가중치 매개변수의 값을 아주 조금 변화시켰을 때, 손실 함수가 어떻게 변하나<br /></p><ul><li>만약 이 미분 값이 음수면 그 가중치 매개변수를 양의 방향으로 변화시켜 손실 함수의 값을 줄일 수 있음.<br /></li><li>반대로, 미분 값이 양수면 가중치 매개변수를 음의 방향으로 변화시켜 손실 함수의 값을 줄일 수 있음.<br /></li><li>그러나 미분 값이 0이면 가중치 매개변수를 어느 쪽으로 움직여도 손실 함수의 값은 줄어들지 않음. 그래서 가중치 매개변수의 갱신은 거기서 멈춤.</li></ul><p><br /></p><p><strong>0074.</strong> 정확도를 지표로 삼아서는 안 되는 이유: 미분 값이 대부분의 장소에서 이 되어 매개변수를 갱신할 수 없음, 불연속적인 띄엄띄엄한 값으로 바뀜.<br /> <br /></p><p><strong>0075.</strong> 정확도는 매개변수의 미소한 변화에는 거의 반응을 보이지 않고, 반응이 있더라도 그 값이 불연속적으로 갑자기 변화함.</p><ul><li>‘계단 함수’를 활성화 함수로 사용하지 않는 이유와도 들어맞음.<br /></li><li>계단 함수는 한순간만 변화를 일으키지만, 시그모이드 함수의 미분(접선)은 출력이 연속적으로 변하고 곡선의 기울이도 연속적으로 변하여 시그모이드 함수의 미분은 어느 장소라도 0이 되지 않음.<br /></li></ul><p><br /></p><hr /><p><br /></p><p><strong>0076.</strong> 미분: 한 순간의 변화량. 함수의 기울기.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://media.vlpt.us/post-images/dscwinterstudy/44ad4090-419c-11ea-bed1-737062fffe57/image.png" alt="img" /></p><ul><li>x의 ‘작은 변화’가 함수 f(x)를 얼마나 변화시키느냐</li></ul><p><br /></p><p><strong>0077.</strong> 수치 미분: 아주 작은 차분으로 미분.<br /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>def numerical_diff(f, x):
  f = 1e-4 # 0.0001
  return (f(x+h) - f(x-h)) / (2*h) # 중심/중앙 차분
</pre></table></code></div></div><p><br /></p><p><strong>0078.</strong> 편미분: 변수가 여럿인 함수에 대한 미분. &lt;- 여러 변수 중 목표 변수 하나에 초점을 맞추고 다른 변수는 값을 고정함.<br /> <br /></p><hr /><p><br /></p><p><strong>0079.</strong> 기울기: 모든 변수의 편미분을 벡터로 정리한 것.<br /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre>def numerical_gradient(f, x):
  h = 1e-4 # 0.0001 
  grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성
  
  for idx in range(x.size):
    tmp_val = x[idx]
    
    # f(x+h) 계산
    x[idx] = tmp_val + h
    fxh1 = f(x)
    
    # f(x-h) 계산
    x[idx] = tmp_val -h
    fxh2 = f(x)
    
    grad[idx] = (fxh1 - fxh2) / (2*h)
    x[idx] = tmp_val # 값 복원
    
  return grad
</pre></table></code></div></div><p><br /></p><p><strong>0080.</strong> 기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향<br /> <br /></p><p><strong>0081.</strong> 경사법은 현 위치에서 기울어진 방향으로 일정 거리만큼 이동.<br /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://media.vlpt.us/post-images/dscwinterstudy/8865d4a0-419c-11ea-af2e-4fe713384e5c/image.png" alt="img" /></p><ul><li>에타(n)는 갱신하는 양. 학습률.</li></ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>def gradient_descent(f, init_x, lr=0.01, step_num=100):
  x = init_x
  
  for i in range(step_num):
    grad = numerical_gradient(f, x)
    x -= lr * grad
  return x
</pre></table></code></div></div><p><br /></p><p><strong>0082.</strong> 학습률 같은 매개변수를 하이퍼파라미터라고 함.<br /> <br /></p><p><strong>0083.</strong> 신경망 학습에서 구하는 기울기는 가중치 매개변수에 대한 손실 함수의 기울기<br /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://media.vlpt.us/post-images/dscwinterstudy/917e2b50-419c-11ea-bed1-737062fffe57/image.png" alt="img" /></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/ai/'>ai</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/ai-basic/" class="post-tag no-text-decoration" >ai basic</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=ai basic 2 - CYM&url=http://0.0.0.0:4000/posts/ab2/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=ai basic 2 - CYM&u=http://0.0.0.0:4000/posts/ab2/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=ai basic 2 - CYM&url=http://0.0.0.0:4000/posts/ab2/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Pannel on right side (Desktop views) v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai-basic/">ai basic</a> <a class="post-tag" href="/tags/function/">function</a> <a class="post-tag" href="/tags/network/">network</a> <a class="post-tag" href="/tags/docker/">docker</a> <a class="post-tag" href="/tags/3d-computer-graphics/">3d computer graphics</a> <a class="post-tag" href="/tags/algorithm/">algorithm</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/ab1/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Jan 14 <i class="unloaded">2021-01-14T22:00:00+00:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ai basic 1</h3><div class="text-muted small"><p> Python 0001. 넘파이는 수치 계산용 라이브러리. 고도의 수학 알고리즘과 배열(행렬) 조작을 위한 편리한 메서드 많음. 0002. matplotlib은 그래프를 그려주는 라이브러리. 0003. 파이썬에는 type() 함수로 특정 데이터의 자료형을 알아볼 수 있음. 0004. 파이썬은 동적 언어. (동적: 변수의 자료형을 ...</p></div></div></a></div><div class="card"> <a href="/posts/ab3/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Jan 16 <i class="unloaded">2021-01-16T22:00:00+00:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ai basic 3</h3><div class="text-muted small"><p> Backpropagation 0084. 수치 미분은 단순하고 구현하기 쉽지만 계산 시간이 오래 걸림-&gt; 가중치 매개변수의 기울기를 효율적으로 계산하는 ‘오차역전파법(backpropagation)’ 0085. 연쇄법칙: 합성 함수의 미분에 대한 성질. 합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있음...</p></div></div></a></div><div class="card"> <a href="/posts/ab4/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Jan 17 <i class="unloaded">2021-01-17T22:00:00+00:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ai basic 4</h3><div class="text-muted small"><p> Learning-related skills 0096. 최적화(optimization): 신경망 학습의 목적은 손실 함수의 값을 가능한 낮추는 매개변수를 찾는 것(매개변수의 최적값을 찾는 문제), 이러한 문제를 푸는 것. 광대하고 복잡한 지형을 지도없이, 눈을 가린 채로 ‘깊은 곳’을 찾아야 함. 이 어려운 상황에서 중요한 단서가 되는 것이...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/ab1/" class="btn btn-outline-primary"><p>ai basic 1</p></a> <a href="/posts/ab3/" class="btn btn-outline-primary"><p>ai basic 3</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script> <!-- The Footer v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://www.linkedin.com/in/yoomee-cho-5844ab202/">CYM</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/">Chirpy</a> theme.</p></div></div></footer></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/ai-basic/">ai basic</a> <a class="post-tag" href="/tags/function/">function</a> <a class="post-tag" href="/tags/network/">network</a> <a class="post-tag" href="/tags/docker/">docker</a> <a class="post-tag" href="/tags/3d-computer-graphics/">3d computer graphics</a> <a class="post-tag" href="/tags/algorithm/">algorithm</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="http://0.0.0.0:4000{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
